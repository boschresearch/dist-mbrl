{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.functional import cartesian_prod\n",
    "\n",
    "from dist_mbrl.agents import EQRSAC\n",
    "from dist_mbrl.utils.common import PathType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_plot = [4, 5, 10, 11, 12]\n",
    "\n",
    "\n",
    "def load_agent(model_dir: PathType, fname: str, device: str = \"cpu\") -> EQRSAC:\n",
    "    model = torch.load(model_dir / fname, map_location=torch.device(device))\n",
    "    return model\n",
    "\n",
    "\n",
    "root_module = Path.cwd()\n",
    "checkpoints_dir = root_module.parent / \"data/trained_mountaincar_checkpoints\"\n",
    "\n",
    "agents = {}\n",
    "for epoch in epochs_to_plot:\n",
    "    prefix = \"agent\"\n",
    "    ext = \"pth\"\n",
    "    agents[epoch] = load_agent(checkpoints_dir, f\"{prefix}_{epoch}.{ext}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each agent, collect a few trajectories to overlay with value plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dist_mbrl.utils.common as utils_common\n",
    "\n",
    "env_params = {\"name\": \"MountainCarContinuous-v0\", \"reward_scale\": 0.5}\n",
    "env, eval_env = utils_common.get_env(env_params)\n",
    "seed = 42\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "rng, generator = utils_common.fix_rng(env, eval_env=eval_env, seed=seed, device=device)\n",
    "\n",
    "reset_bounds = {\"low\": -0.5, \"high\": -0.5}\n",
    "trajectories_per_agent = 10\n",
    "steps_per_epoch = 1000\n",
    "trajectories = {}\n",
    "empirical_values = {}\n",
    "\n",
    "for episode in epochs_to_plot:\n",
    "    agents[episode].device = device\n",
    "    agents[episode].actor.device = device\n",
    "    for i in range(trajectories_per_agent):\n",
    "        obs, _ = env.reset(options=reset_bounds)\n",
    "        terminated = False\n",
    "        episode_return = 0\n",
    "        step = 0\n",
    "        trajectory = []\n",
    "        returns = []\n",
    "        while not (terminated or step >= steps_per_epoch):\n",
    "            action = agents[episode].act(obs)\n",
    "            trajectory.append(obs)\n",
    "            next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_return += (agents[episode].gamma ** step) * reward\n",
    "            obs = next_obs\n",
    "            step += 1\n",
    "\n",
    "        trajectory.append(obs)\n",
    "        returns.append(episode_return)\n",
    "        trajectories[(episode, i)] = np.array(trajectory)\n",
    "    empirical_values[episode] = np.mean(np.array(returns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build inputs for the agent's networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pos = 0.5\n",
    "min_pos = -1.2\n",
    "max_vel = 0.07\n",
    "num_pos = 100\n",
    "num_vels = 100\n",
    "positions = np.linspace(min_pos, max_pos, num_pos)\n",
    "vels = np.linspace(-max_vel, max_vel, num_vels)\n",
    "\n",
    "\n",
    "def build_function_inputs(disc_pos, disc_vels):\n",
    "    pos = torch.Tensor(disc_pos)\n",
    "    vels = torch.Tensor(disc_vels)\n",
    "    inputs = cartesian_prod(pos, vels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Inputs to be fed into distributional critic\n",
    "inputs = build_function_inputs(positions, vels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize things, we need the state-value function, not the state-action value function\n",
    "# We approximate the state-value function by passing the mean actions through the critic\n",
    "# In other words, we visualize the Q-values for the mean actions\n",
    "mean_values = {}\n",
    "std_values = {}\n",
    "quantiles_init_state = {}\n",
    "init_state, _ = eval_env.reset(options=reset_bounds)\n",
    "init_state = torch.from_numpy(init_state).float().to(device)\n",
    "init_state = init_state.unsqueeze(dim=0)\n",
    "\n",
    "for epoch in epochs_to_plot:\n",
    "    agent = agents[epoch]\n",
    "    mean_actions, log_std = agent.actor.forward(inputs)\n",
    "    quantiles = agent.get_min_q(inputs, mean_actions, agent.critic)\n",
    "    mean_values[epoch] = torch.mean(quantiles, dim=-1)\n",
    "    std_values[epoch] = torch.std(quantiles, dim=-1)\n",
    "\n",
    "    # also get quantiles at initial state\n",
    "    act = torch.from_numpy(agent.act(init_state, sample=False)).float().to(device)\n",
    "\n",
    "    quantiles_init_state[epoch] = (\n",
    "        agent.critic(init_state, act).detach().numpy().squeeze()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.colors import Colormap\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from dist_mbrl.utils.plot import JMLR_PARAMS\n",
    "\n",
    "plt.rcParams.update(JMLR_PARAMS)\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def fix_white_lines(cnt):\n",
    "    for c in cnt.collections:\n",
    "        c.set_edgecolor(\"face\")\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def plot_function_contour(\n",
    "    ax: Axes,\n",
    "    values: torch.Tensor,\n",
    "    colormap: Colormap = cm.coolwarm,\n",
    "    minmax_values: tuple = None,\n",
    "    show_colorbar: bool = True,\n",
    "):\n",
    "    num_levels = 100\n",
    "    values = torch.reshape(values, (num_pos, num_vels)).detach().numpy().transpose()\n",
    "    xaxis, yaxis = np.meshgrid(positions, vels)\n",
    "    if minmax_values:\n",
    "        min_value = minmax_values[0]\n",
    "        max_value = minmax_values[1]\n",
    "    else:\n",
    "        min_value = np.min(values)\n",
    "        max_value = np.max(values)\n",
    "\n",
    "    levels = np.linspace(min_value, max_value, num_levels)\n",
    "    data = fix_white_lines(\n",
    "        ax.contourf(xaxis, yaxis, values, levels=levels, cmap=colormap)\n",
    "    )\n",
    "    mid_value = np.mean([min_value, max_value])\n",
    "    ticks = [min_value, mid_value, max_value]\n",
    "    cbar = plt.colorbar(data, ax=ax, format=lambda x, _: f\"{x:.1f}\", ticks=ticks)\n",
    "    if not show_colorbar:\n",
    "        cbar.remove()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6.3, 3.5))\n",
    "ncols = len(epochs_to_plot)\n",
    "\n",
    "# Alternate way of plotting on grid to have independent control over axis padding, width, etc.\n",
    "gs_top = plt.GridSpec(\n",
    "    nrows=3, ncols=ncols + 1, hspace=1.0, wspace=0.2, width_ratios=[1, 1, 1, 1, 1, 0.1]\n",
    ")\n",
    "gs_bottom = plt.GridSpec(\n",
    "    nrows=3, ncols=ncols, hspace=0.15, wspace=0.09, width_ratios=[1, 1, 1, 1, 1.2]\n",
    ")\n",
    "axes = np.empty((3, ncols), dtype=object)\n",
    "for i in range(ncols):\n",
    "    axes[0, i] = fig.add_subplot(gs_top[0, i])\n",
    "    axes[1, i] = fig.add_subplot(gs_bottom[1, i])\n",
    "    axes[2, i] = fig.add_subplot(gs_bottom[2, i])\n",
    "\n",
    "quantiles_axes = axes[0, :]\n",
    "mean_values_axes = axes[1, :]\n",
    "std_values_axes = axes[2, :]\n",
    "\n",
    "# Get min-max values of mean and std of values to have common colorbar\n",
    "min_mean_value = np.min([torch.min(v).item() for v in mean_values.values()])\n",
    "max_mean_value = np.max([torch.max(v).item() for v in mean_values.values()])\n",
    "minmax_mean_value = (min_mean_value, max_mean_value)\n",
    "\n",
    "min_std_value = np.min([torch.min(v).item() for v in std_values.values()])\n",
    "max_std_value = np.max([torch.max(v).item() for v in std_values.values()])\n",
    "minmax_std_value = (min_std_value, max_std_value)\n",
    "\n",
    "for i, episode in enumerate(epochs_to_plot):\n",
    "    show_color_bar = (i + 1) == len(epochs_to_plot)\n",
    "    plot_function_contour(\n",
    "        mean_values_axes[i],\n",
    "        mean_values[episode],\n",
    "        minmax_values=minmax_mean_value,\n",
    "        show_colorbar=show_color_bar,\n",
    "    )\n",
    "    plot_function_contour(\n",
    "        std_values_axes[i],\n",
    "        std_values[episode],\n",
    "        colormap=cm.viridis,\n",
    "        minmax_values=minmax_std_value,\n",
    "        show_colorbar=show_color_bar,\n",
    "    )\n",
    "\n",
    "# Plot trajectories on top of value plots\n",
    "for i, episode in enumerate(epochs_to_plot):\n",
    "    for j in range(trajectories_per_agent):\n",
    "        traj = trajectories[(episode, j)]\n",
    "        mean_values_axes[i].plot(traj[:, 0], traj[:, 1], c=\"k\", alpha=0.2)\n",
    "\n",
    "# Plot initial state value distributions\n",
    "x = np.linspace(-100, 100, 5000)\n",
    "for i, episode in enumerate(epochs_to_plot):\n",
    "    data = quantiles_init_state[episode]\n",
    "    empirical_value = empirical_values[episode]\n",
    "    kernel = stats.gaussian_kde(data)\n",
    "    quantiles_axes[i].plot(x, kernel.pdf(x), color=\"tab:red\", lw=2.0)\n",
    "    quantiles_axes[i].axvline(empirical_value, c=\"g\", ls=\"--\")\n",
    "\n",
    "# Manage top axes\n",
    "axes[0, 0].set_ylabel(\"Prob.\" + \"\\n\" + \"density\")\n",
    "for ax in axes[0, :].flatten():\n",
    "    ax.set_xlabel(r\"$V(s_0)$\", labelpad=-2)\n",
    "\n",
    "for ax in quantiles_axes:\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticks([])\n",
    "\n",
    "for ax in quantiles_axes[:2]:\n",
    "    ax.set_xticks([-0, 100])\n",
    "\n",
    "for ax in quantiles_axes[2:]:\n",
    "    ax.set_xlim(right=50, left=-10)\n",
    "\n",
    "# Manage two bottom axes\n",
    "for ax in axes[-2:, 1:].flatten():\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "\n",
    "for ax in axes[-2:-1, :].flatten():\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "\n",
    "for epoch, ax in zip(epochs_to_plot, axes[0, :].flatten()):\n",
    "    ax.set_title(rf\"\\textbf{{{epoch}K steps}}\")\n",
    "\n",
    "for ax in axes[-2:, 0].flatten():\n",
    "    ax.set_ylabel(r\"$\\dot{x}$ [m/s]\")\n",
    "\n",
    "for ax in axes[-1, :].flatten():\n",
    "    ax.set_xlabel(r\"$x$ [m]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = root_module.parent.joinpath(\"figures/mountaincar_value_viz.pdf\")\n",
    "fig.savefig(fig_dir, bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    ">Copyright (c) 2024 Robert Bosch GmbH\n",
    ">\n",
    ">This program is free software: you can redistribute it and/or modify <br>\n",
    ">it under the terms of the GNU Affero General Public License as published<br>\n",
    ">by the Free Software Foundation, either version 3 of the License, or<br>\n",
    ">(at your option) any later version.<br>\n",
    ">\n",
    ">This program is distributed in the hope that it will be useful,<br>\n",
    ">but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n",
    ">MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n",
    ">GNU Affero General Public License for more details.<br>\n",
    ">\n",
    ">You should have received a copy of the GNU Affero General Public License<br>\n",
    ">along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eafbab267a141d6ae36124cd41d75a3d6551e2f58d4e70cbe0f075109478ae80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ube_mbrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
