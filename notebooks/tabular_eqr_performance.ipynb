{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from dist_mbrl.envs.toy_mdp import ToyMDP1\n",
    "\n",
    "# Set Seeds\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to build posterior MDPs and compute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define posterior over the three parameters defining the toy MRP\n",
    "def build_posterior(alphas, beta):\n",
    "    p = []\n",
    "    r = []\n",
    "    for alpha in alphas:\n",
    "        mdp = ToyMDP1(alpha, beta)\n",
    "        p.append(mdp.p)\n",
    "        r.append(mdp.r)\n",
    "    return np.array(p), np.array(r)\n",
    "\n",
    "\n",
    "def compute_values(p_ensemble, r_ensemble, discount=0.99):\n",
    "    num_models = p_ensemble.shape[0]\n",
    "    vfs = []\n",
    "    for i in range(num_models):\n",
    "        p = p_ensemble[i]\n",
    "        r = r_ensemble[i]\n",
    "        vfs.append(np.linalg.inv(np.eye(p.shape[0]) - discount * p).dot(r))\n",
    "    return np.stack([value for value in vfs], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example posteriors to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.0\n",
    "num_samples = 5000\n",
    "\n",
    "alphas = []\n",
    "# First: standard Gaussian\n",
    "alphas.append(\n",
    "    np.clip(stats.norm.rvs(loc=0.5, scale=0.1, size=num_samples), a_min=0.0, a_max=1.0)\n",
    ")\n",
    "\n",
    "# Second: multimodal distribution\n",
    "alphas.append(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            np.clip(\n",
    "                stats.norm.rvs(loc=0.3, scale=0.03, size=int(np.ceil(num_samples / 2))),\n",
    "                a_min=0.0,\n",
    "                a_max=1.0,\n",
    "            ),\n",
    "            np.clip(\n",
    "                stats.norm.rvs(loc=0.6, scale=0.05, size=int(np.ceil(num_samples / 2))),\n",
    "                a_min=0.0,\n",
    "                a_max=1.0,\n",
    "            ),\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# third: heavy-tailed\n",
    "alphas.append(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            np.clip(\n",
    "                stats.norm.rvs(loc=0.3, scale=0.03, size=int(np.ceil(num_samples / 2))),\n",
    "                a_min=0.0,\n",
    "                a_max=1.0,\n",
    "            ),\n",
    "            np.clip(\n",
    "                stats.norm.rvs(loc=0.5, scale=0.15, size=int(np.ceil(num_samples / 2))),\n",
    "                a_min=0.0,\n",
    "                a_max=1.0,\n",
    "            ),\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "p_all, r_all, vf_true_all = [], [], []\n",
    "for alpha in alphas:\n",
    "    p, r = build_posterior(alpha, beta)\n",
    "    p_all.append(p)\n",
    "    r_all.append(r)\n",
    "    vf_true_all.append(compute_values(p, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value-Distributional Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUANTILES = 10\n",
    "ENSEMBLE_SIZE = 1\n",
    "NUM_STATES = p.shape[1]\n",
    "tau = (2 * np.arange(NUM_QUANTILES) + 1) / (2.0 * NUM_QUANTILES)\n",
    "\n",
    "\n",
    "def get_quantiles(values, num_quantiles):\n",
    "    values = np.sort(values)\n",
    "    quant_levels = (2 * np.arange(len(values)) + 1) / (2.0 * len(values))\n",
    "    target_levels = (2 * np.arange(num_quantiles) + 1) / (2.0 * num_quantiles)\n",
    "    idx = [np.abs(quant_levels - level).argmin() for level in target_levels]\n",
    "    return values[idx]\n",
    "\n",
    "\n",
    "def dist_value_iteration(\n",
    "    alphas, beta, num_quantiles, max_iter=int(1e4), gamma=0.99, lr=5e-3, epsilon=1e-8\n",
    "):\n",
    "    # Random init guess of the value distribution function\n",
    "    # Force terminal state to have a value of zero\n",
    "    theta_i = 1 * np.sort(np.random.rand(num_quantiles, NUM_STATES), axis=0)\n",
    "    theta_i[:, -1] *= 0\n",
    "\n",
    "    theta_list = [theta_i]\n",
    "    for _ in range(max_iter):\n",
    "        # First: sample models from the posterior to estimate the gradient\n",
    "        alphas_ens = np.random.choice(alphas, size=ENSEMBLE_SIZE)\n",
    "        p, r = build_posterior(alphas_ens, beta)\n",
    "\n",
    "        # Second: Compute the gradient of the quantile regression loss\n",
    "        theta_j = np.expand_dims(r, axis=1) + gamma * np.einsum(\n",
    "            \"eij, mj -> emi\", p, theta_i\n",
    "        )\n",
    "        theta_j = np.expand_dims(theta_j, axis=1)\n",
    "        tmp = np.expand_dims(theta_i, axis=(0, 2))\n",
    "        indicator_fn = (theta_j - tmp < 0).astype(float)\n",
    "        grad_loss = np.expand_dims(tau, axis=(0, -2, -1)) - indicator_fn\n",
    "        grad_loss = np.mean(grad_loss, axis=(0, 2))\n",
    "\n",
    "        # Update the params by taking a step in the direction of the gradient\n",
    "        new_theta_i = theta_i + lr * grad_loss\n",
    "        theta_list.append(new_theta_i)\n",
    "        if np.any(np.abs(theta_i - new_theta_i) > epsilon):\n",
    "            theta_i = new_theta_i\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return theta_i, theta_list\n",
    "\n",
    "\n",
    "true_quantiles = []\n",
    "pred_quantiles = []\n",
    "for alpha, vf_true in zip(alphas, vf_true_all):\n",
    "    true_quantiles.append(get_quantiles(vf_true[:, 0], NUM_QUANTILES))\n",
    "    pred_quantiles.append(dist_value_iteration(alpha, beta, NUM_QUANTILES)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare QR errors for different values of beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.linspace(0, 1, 50)\n",
    "wass_ipms = []\n",
    "for alpha in alphas:\n",
    "    wass_ipm = np.zeros_like(betas)\n",
    "    for i, beta in enumerate(betas):\n",
    "        p, r = build_posterior(alpha, beta)\n",
    "        vf_true = compute_values(p, r)\n",
    "        true_q = get_quantiles(vf_true[:, 0], NUM_QUANTILES)\n",
    "        pred_q = dist_value_iteration(alpha, beta, NUM_QUANTILES)[-1]\n",
    "        # Compute 1-Wasserstein metric between\n",
    "        wass_ipm[i] = (1 / NUM_QUANTILES) * np.sum(np.abs(true_q - pred_q[-1][:, 0]))\n",
    "    wass_ipms.append(wass_ipm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dist_mbrl.utils.plot import JMLR_PARAMS\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "plt.rcParams.update(JMLR_PARAMS)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=3, figsize=(6.5, 4.5), gridspec_kw={\"wspace\": 0.30, \"hspace\": 0.7}\n",
    ")\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "for i, (vf_true, true_q, pred_q) in enumerate(\n",
    "    zip(vf_true_all, true_quantiles, pred_quantiles)\n",
    "):\n",
    "    # Plot the value posterior\n",
    "    kernel_true = stats.gaussian_kde(vf_true[:, 0])\n",
    "    axes[0, i].plot(\n",
    "        x, kernel_true.pdf(x), color=\"tab:blue\", linewidth=2.0, label=\"true\"\n",
    "    )\n",
    "    theta = np.array(pred_q)\n",
    "    x_grad = np.linspace(0, 1, theta.shape[0])\n",
    "    for j in range(NUM_QUANTILES):\n",
    "        axes[1, i].plot(\n",
    "            x_grad,\n",
    "            true_q[j] - theta[:, j, 0],\n",
    "            c=cmap(j),\n",
    "            linestyle=\"-\",\n",
    "            lw=1.5,\n",
    "            alpha=0.4,\n",
    "        )\n",
    "        axes[1, i].axhline(0.0, c=\"k\", linestyle=\"--\", lw=1.5)\n",
    "\n",
    "    axes[0, i].set_xlabel(r\"$V(s_0)$\", labelpad=-0.5)\n",
    "    axes[1, i].ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0, 0))\n",
    "    axes[1, i].set_xlabel(r\"Gradient steps $(\\times 10^4)$\")\n",
    "\n",
    "for i, wass_ipm in enumerate(wass_ipms):\n",
    "    axes[2, i].plot(betas, wass_ipm, linestyle=\"-\", lw=1.5)\n",
    "    axes[2, i].set_xlabel(r\"$\\beta$\")\n",
    "\n",
    "axes[0, 0].set_ylabel(r\"$\\mu(s_0)$\" + \"\\n\" + r\"($\\beta=0$)\")\n",
    "axes[1, 0].set_ylabel(\"Quantile error\" + \"\\n\" + r\"($\\beta=0$)\")\n",
    "axes[2, 0].set_ylabel(\"QR error\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_module = Path.cwd()\n",
    "fig_dir = root_module.parent.joinpath(\"figures/tabular_eqr_performance.pdf\")\n",
    "fig.savefig(fig_dir, bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    ">Copyright (c) 2024 Robert Bosch GmbH\n",
    ">\n",
    ">This program is free software: you can redistribute it and/or modify <br>\n",
    ">it under the terms of the GNU Affero General Public License as published<br>\n",
    ">by the Free Software Foundation, either version 3 of the License, or<br>\n",
    ">(at your option) any later version.<br>\n",
    ">\n",
    ">This program is distributed in the hope that it will be useful,<br>\n",
    ">but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n",
    ">MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n",
    ">GNU Affero General Public License for more details.<br>\n",
    ">\n",
    ">You should have received a copy of the GNU Affero General Public License<br>\n",
    ">along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d44ccd9663ca780629f4890d49070f732c0f5e9dadc4d8a50f711cbdaf1c170b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('dist_mbrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
