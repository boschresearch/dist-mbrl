{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from gymnasium.wrappers.compatibility import EnvCompatibility\n",
    "from rlberry.envs.benchmarks.grid_exploration.nroom import NRoom\n",
    "from rlberry.seeding import Seeder, safe_reseed\n",
    "\n",
    "import dist_mbrl.tabular.util as util\n",
    "from dist_mbrl.mbrl.util import ReplayBuffer\n",
    "from dist_mbrl.tabular.agents import TabularAgent\n",
    "from dist_mbrl.tabular.config import base_default_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = base_default_parameters\n",
    "env = EnvCompatibility(\n",
    "    NRoom(\n",
    "        nrooms=3,\n",
    "        room_size=5,\n",
    "        success_probability=1.0,\n",
    "        initial_state_distribution=\"center\",\n",
    "    )\n",
    ")\n",
    "obs_shape = (1,)\n",
    "act_shape = (1,)\n",
    "\n",
    "# Fix RNG\n",
    "seed = 42\n",
    "rng = util.fix_rng(seed=seed)\n",
    "safe_reseed(env.env, Seeder(seed))\n",
    "\n",
    "# Task horizon\n",
    "steps_per_episode = 20\n",
    "\n",
    "agent = TabularAgent(\n",
    "    env.observation_space.n, env.action_space.n, params=parameters[\"agent\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "root_module = Path.cwd()\n",
    "ext = \".pkl\"\n",
    "name = \"nroom_policy\"\n",
    "file_dir = root_module.parent.joinpath(\"data/\" + name + ext)\n",
    "\n",
    "data = pickle.load(open(file_dir, \"rb\"))\n",
    "optimal_policy = data[\"opt_policy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Env data and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "warmup_episodes = 0\n",
    "num_episodes = 100\n",
    "episode_to_record = [1, 10, 100]\n",
    "reward_scale = 1\n",
    "agents = []\n",
    "ep_returns = np.zeros(warmup_episodes + num_episodes)\n",
    "agent.pi = optimal_policy\n",
    "for i in range(warmup_episodes + num_episodes):\n",
    "    if i < warmup_episodes:\n",
    "        random_actions = np.random.choice(agent.num_actions, agent.num_states)\n",
    "        agent.pi = agent.actions_to_policy_matrix(random_actions)\n",
    "    else:\n",
    "        agent.pi = optimal_policy\n",
    "\n",
    "    ep_buffer = ReplayBuffer(\n",
    "        steps_per_episode,\n",
    "        obs_shape,\n",
    "        act_shape,\n",
    "        obs_type=np.int32,\n",
    "        action_type=np.int32,\n",
    "        rng=rng,\n",
    "    )\n",
    "    obs, _ = env.reset()\n",
    "    initial_state = obs\n",
    "    ep_step = 0\n",
    "    terminated = False\n",
    "    while (not terminated) and (ep_step < steps_per_episode):\n",
    "        action = agent.act(obs)\n",
    "        next_obs, reward, terminated, *_ = env.step(action)\n",
    "        if reward == 1:\n",
    "            terminated = True\n",
    "        ep_buffer.add(obs, action, next_obs, reward_scale * reward, terminated)\n",
    "        ep_returns[i] += (agent.gamma**ep_step) * (reward_scale * reward)\n",
    "        obs = next_obs\n",
    "        ep_step += 1\n",
    "\n",
    "    # Update agent's MDP posterior\n",
    "    agent.update_posterior_mdp(ep_buffer)\n",
    "\n",
    "    # Record agent\n",
    "    if (i - warmup_episodes + 1) in episode_to_record:\n",
    "        agents.append(deepcopy(agent))\n",
    "\n",
    "# Get empirical estimate of value at initial state\n",
    "opt_value = np.mean(ep_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "\n",
    "def compute_value_ensemble(num_samples, agent) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns an ensemble of V-functions and Q-functions of the same size as the ensemble of\n",
    "    transition models passed as argument to the function.\n",
    "    \"\"\"\n",
    "    ensemble = agent.sample_ensemble_from_posterior(num_samples)\n",
    "    p_ensemble, r_ensemble = ensemble\n",
    "    num_models = p_ensemble.shape[0]\n",
    "    vfs, qfs = [], []\n",
    "    for i in range(num_models):\n",
    "        p = p_ensemble[i]\n",
    "        r = r_ensemble[i]\n",
    "        vf, qf = util.solve_bellman_eq(p, r, agent.pi, agent.gamma)\n",
    "        vfs.append(vf)\n",
    "        qfs.append(qf)\n",
    "    v_ensemble = np.stack([value for value in vfs], axis=0)\n",
    "    return v_ensemble, p_ensemble, r_ensemble\n",
    "\n",
    "\n",
    "vf = []\n",
    "for i, agent in enumerate(agents):\n",
    "    v_ensemble, p_ensemble, r_ensemble = compute_value_ensemble(num_samples, agent)\n",
    "    vf.append(v_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value distribution via Quantile regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUANTILES = 100\n",
    "ENSEMBLE_SIZE = 1\n",
    "NUM_STATES = vf[0].shape[1]\n",
    "tau = (2 * np.arange(NUM_QUANTILES) + 1) / (2.0 * NUM_QUANTILES)\n",
    "\n",
    "\n",
    "def get_quantiles(values, num_quantiles):\n",
    "    values = np.sort(values)\n",
    "    quant_levels = (2 * np.arange(len(values)) + 1) / (2.0 * len(values))\n",
    "    target_levels = (2 * np.arange(num_quantiles) + 1) / (2.0 * num_quantiles)\n",
    "    idx = [np.abs(quant_levels - level).argmin() for level in target_levels]\n",
    "    return values[idx]\n",
    "\n",
    "\n",
    "def dist_value_iteration(\n",
    "    agent: TabularAgent,\n",
    "    num_quantiles,\n",
    "    max_iter=int(1e4),\n",
    "    gamma=0.99,\n",
    "    lr=5e-1,\n",
    "    epsilon=1e-8,\n",
    "):\n",
    "    # Random init guess of the value distribution function\n",
    "    # Force terminal state to have a value of zero\n",
    "    theta_i = 1 * np.sort(np.random.rand(num_quantiles, NUM_STATES), axis=0)\n",
    "    theta_i[:, -1] *= 0\n",
    "\n",
    "    theta_list = [theta_i]\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # First: sample models from the posterior to estimate the gradient\n",
    "        p, r = agent.sample_ensemble_from_posterior(num_samples=ENSEMBLE_SIZE)\n",
    "        r_pi = np.einsum(\"eij, ij -> ei\", r, agent.pi)\n",
    "        p_pi = np.einsum(\"eijk, ij -> eik\", p, agent.pi)\n",
    "\n",
    "        # Second: Compute the gradient of the quantile regression loss\n",
    "        theta_j = np.expand_dims(r_pi, axis=1) + gamma * np.einsum(\n",
    "            \"eij, mj -> emi\", p_pi, theta_i\n",
    "        )\n",
    "        theta_j = np.expand_dims(theta_j, axis=1)\n",
    "        tmp = np.expand_dims(theta_i, axis=(0, 2))\n",
    "        indicator_fn = (theta_j - tmp < 0).astype(float)\n",
    "        grad_loss = np.expand_dims(tau, axis=(0, -2, -1)) - indicator_fn\n",
    "        grad_loss = np.mean(grad_loss, axis=(0, 2))\n",
    "\n",
    "        # Update the params by taking a step in the direction of the gradient\n",
    "        new_theta_i = theta_i + lr * grad_loss\n",
    "        theta_list.append(new_theta_i)\n",
    "        new_theta_i[:, -1] *= 0\n",
    "        if np.any(np.abs(theta_i - new_theta_i) > epsilon):\n",
    "            theta_i = new_theta_i\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return theta_i, theta_list\n",
    "\n",
    "\n",
    "true_quantiles = []\n",
    "pred_quantiles = []\n",
    "wass_ipm = []\n",
    "for i, agent in enumerate(agents):\n",
    "    true_quantiles.append(get_quantiles(vf[i][:, initial_state], NUM_QUANTILES))\n",
    "    pred_quantiles.append(\n",
    "        dist_value_iteration(agent, NUM_QUANTILES, gamma=agent.gamma)[-1]\n",
    "    )\n",
    "    theta = np.array(pred_quantiles[i])\n",
    "    wass = (1 / NUM_QUANTILES) * np.sum(\n",
    "        np.abs(true_quantiles[i] - theta[:, :, initial_state]), axis=1\n",
    "    )\n",
    "    wass_ipm.append(wass)\n",
    "\n",
    "for wass in wass_ipm:\n",
    "    print(wass[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dist_mbrl.utils.plot import JMLR_PARAMS\n",
    "\n",
    "plt.rcParams.update(JMLR_PARAMS)\n",
    "\n",
    "fig = plt.figure(figsize=(6.5, 3.5))\n",
    "\n",
    "# Alternate way of plotting on grid to have independent control over axis padding, width, etc.\n",
    "gs_top = plt.GridSpec(nrows=3, ncols=3, hspace=0.0, wspace=0.3, bottom=0.13)\n",
    "gs_bottom = plt.GridSpec(nrows=3, ncols=3, hspace=0.6, wspace=0.3)\n",
    "axes = np.empty((3, 3), dtype=object)\n",
    "for i in range(3):\n",
    "    axes[0, i] = fig.add_subplot(gs_top[0, i])\n",
    "    axes[1, i] = fig.add_subplot(gs_top[1, i])\n",
    "    axes[2, i] = fig.add_subplot(gs_bottom[2, i])\n",
    "\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "for i in range(len(agents)):\n",
    "    # First plot: ground-truth value distribution\n",
    "    x = np.linspace(-15, 15, 5000)\n",
    "    theta = np.array(pred_quantiles[i])\n",
    "    kernel_v = stats.gaussian_kde(vf[i][:, initial_state])\n",
    "    axes[0, i].plot(\n",
    "        x,\n",
    "        kernel_v.pdf(x),\n",
    "        color=\"tab:blue\",\n",
    "        lw=2.0,\n",
    "        ls=\"--\",\n",
    "        dashes=(5, 1),\n",
    "        label=r\"$\\mu^{\\pi^\\star}(s_0)$\",\n",
    "    )\n",
    "    kernel_v = stats.gaussian_kde(theta[-1, :, initial_state])\n",
    "    axes[0, i].plot(\n",
    "        x, kernel_v.pdf(x), color=\"tab:orange\", lw=2.0, label=r\"$\\mu_q(s_0)$\"\n",
    "    )\n",
    "    axes[0, i].axvline(opt_value, c=\"g\", ls=\":\", label=r\"$v^{\\pi^\\star, p}(s_0)$\")\n",
    "    axes[0, i].set_title(rf\"\\textbf{{Episode {{{episode_to_record[i]}}}\")\n",
    "    axes[0, i].set_xticks([-15, 15])\n",
    "    axes[0, i].set_xlim([-15, 15])\n",
    "    axes[0, i].set_xticklabels([])\n",
    "\n",
    "    # Second plot: ground-truth CDF versus our method's estimate\n",
    "    N = 1\n",
    "    mean_quantiles = np.mean(np.sort(theta[-N:, :, initial_state]), axis=0)\n",
    "    axes[1][i].plot(\n",
    "        np.sort(vf[i][:, initial_state]),\n",
    "        np.linspace(0, 1, len(vf[i][:, initial_state]), endpoint=False),\n",
    "        ls=\"--\",\n",
    "        lw=2.0,\n",
    "        dashes=(5, 1),\n",
    "        c=\"tab:blue\",\n",
    "    )\n",
    "    axes[1][i].plot(mean_quantiles, tau, c=\"tab:orange\", lw=2.0)\n",
    "    axes[1, i].axvline(opt_value, c=\"g\", ls=\":\")\n",
    "    axes[1][i].set_xlabel(r\"$V^{\\pi^\\star}(s_0)$\", labelpad=-10)\n",
    "    axes[1][i].set_xlim([-15, 15])\n",
    "    axes[1][i].set_ylim(top=1.2)\n",
    "    axes[1][i].set_xticks([-15, 15])\n",
    "\n",
    "    # Third plot: wasserstein distance between our prediction and the true projection\n",
    "    x_grad = np.linspace(0, 1, theta.shape[0])\n",
    "    axes[2][i].plot(x_grad, wass_ipm[i], c=\"tab:red\", ls=\"-\", lw=1.0)\n",
    "    axes[2][i].ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0, 0))\n",
    "    axes[2, i].set_ylim(top=2, bottom=0)\n",
    "    axes[2][i].set_xlabel(r\"Gradient steps $(\\times 10^4)$\")\n",
    "\n",
    "axes[0][0].legend(loc=\"lower center\", ncol=3, bbox_to_anchor=(1.8, -3.0), frameon=False)\n",
    "\n",
    "axes[0][0].set_ylabel(\"Prob.\" + \"\\n\" + \"density\")\n",
    "axes[1][0].set_ylabel(\"Cumulative\" + \"\\n\" + \"Prob.\")\n",
    "axes[2][0].set_ylabel(\"QR error\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = root_module.parent.joinpath(\"figures/tabular_nroom.pdf\")\n",
    "fig.savefig(fig_dir, bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    ">Copyright (c) 2024 Robert Bosch GmbH\n",
    ">\n",
    ">This program is free software: you can redistribute it and/or modify <br>\n",
    ">it under the terms of the GNU Affero General Public License as published<br>\n",
    ">by the Free Software Foundation, either version 3 of the License, or<br>\n",
    ">(at your option) any later version.<br>\n",
    ">\n",
    ">This program is distributed in the hope that it will be useful,<br>\n",
    ">but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n",
    ">MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n",
    ">GNU Affero General Public License for more details.<br>\n",
    ">\n",
    ">You should have received a copy of the GNU Affero General Public License<br>\n",
    ">along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d44ccd9663ca780629f4890d49070f732c0f5e9dadc4d8a50f711cbdaf1c170b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('dist_mbrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
